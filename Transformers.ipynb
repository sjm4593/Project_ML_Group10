{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combines all the results from all the experiments involving transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==3.3.1\n",
    "!pip install fastcore==1.0.13\n",
    "!pip install wandb==0.10.5\n",
    "!git clone https://github.com/NirantK/Hinglish.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Hinglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hinglishutils import get_files_from_gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Ki6v1a1jF79qx22gM6JlX1NVD4txTdn\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/train_lm.txt\n",
      "100%|██████████| 41.2M/41.2M [00:00<00:00, 91.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-MRU7w2_la36qopO8Ob4BoCynOAZc0sZ\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/dev_lm.txt\n",
      "100%|██████████| 4.59M/4.59M [00:00<00:00, 41.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-NqiU-tL5hW59MFtUXh1exivRokZKfs7\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/test_lm.txt\n",
      "100%|██████████| 5.09M/5.09M [00:00<00:00, 51.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-Ki6v1a1jF79qx22gM6JlX1NVD4txTdn/view?usp=sharing\", \n",
    "                      \"train_lm.txt\")\n",
    "\n",
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-MRU7w2_la36qopO8Ob4BoCynOAZc0sZ/view?usp=sharing\", \n",
    "                      \"dev_lm.txt\")\n",
    "\n",
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-NqiU-tL5hW59MFtUXh1exivRokZKfs7/view?usp=sharing\", \n",
    "                      \"test_lm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1k4N0JlVOP-crIcCtC6ZI5Va8X3s2-r_D\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/test_labels_hinglish.txt\n",
      "100%|██████████| 46.2k/46.2k [00:00<00:00, 35.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1k4N0JlVOP-crIcCtC6ZI5Va8X3s2-r_D/view?usp=sharing\", \n",
    "                      \"test_labels_hinglish.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-FykBMdD7erRhr9370thtySNm6QvnQAA\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/train.json\n",
      "100%|██████████| 4.45M/4.45M [00:00<00:00, 43.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-F6o4lSub2D-_iCoNPvxxnCiPQ82VJjG\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/test.json\n",
      "100%|██████████| 1.11M/1.11M [00:00<00:00, 22.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Esp4UtIZwX44eI8qndngweKZ6p9GLKT\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/valid.json\n",
      "100%|██████████| 985k/985k [00:00<00:00, 22.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17wFvtj9tfp4QI6FrErAyqL9H1s5-lZkR\n",
      "To: /home/stu12/s5/ew9170/ML/Project_ML_Group10/final_test.json\n",
      "100%|██████████| 1.00M/1.00M [00:00<00:00, 20.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-FykBMdD7erRhr9370thtySNm6QvnQAA/view?usp=sharing\", \n",
    "                      \"train.json\")\n",
    "\n",
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-F6o4lSub2D-_iCoNPvxxnCiPQ82VJjG/view?usp=sharing\", \n",
    "                      \"test.json\")\n",
    "\n",
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-Esp4UtIZwX44eI8qndngweKZ6p9GLKT/view?usp=sharing\", \n",
    "                      \"valid.json\")\n",
    "\n",
    "get_files_from_gdrive(\"https://drive.google.com/file/d/17wFvtj9tfp4QI6FrErAyqL9H1s5-lZkR/view?usp=sharing\", \n",
    "                      \"final_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permission denied: https://drive.google.com/uc?id=1-0bVrbhQ3nJhwmgIdhuL-ws4V9zuFpMF\n",
      "Maybe you need to change permission over 'Anyone with the link'?\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hinglishBert.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_files_from_gdrive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://drive.google.com/file/d/1-0bVrbhQ3nJhwmgIdhuL-ws4V9zuFpMF/view?usp=sharing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhinglishBert.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/Project_ML_Group10/hinglishutils.py:95\u001b[0m, in \u001b[0;36mget_files_from_gdrive\u001b[0;34m(url, fname)\u001b[0m\n\u001b[1;32m     93\u001b[0m gdown\u001b[38;5;241m.\u001b[39mdownload(url, fname, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     tf \u001b[38;5;241m=\u001b[39m \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     tf\u001b[38;5;241m.\u001b[39mextractall()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/tarfile.py:1783\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     saved_pos \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ReadError, CompressionError):\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/tarfile.py:1847\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompressionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip module is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1847\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hinglishBert.tar'"
     ]
    }
   ],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1-0bVrbhQ3nJhwmgIdhuL-ws4V9zuFpMF/view?usp=sharing\", \"hinglishBert.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1I1JXDg8ZzuuzXMN1X986oCeOjSxqZj7C/view?usp=sharing\", \n",
    "                      \"hinglishDistilBert.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permission denied: https://drive.google.com/uc?id=1TTJzXi0dWYHVCrZM8vWoZzKWPfIF0ErB\n",
      "Maybe you need to change permission over 'Anyone with the link'?\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hinglishRoberta.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_files_from_gdrive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://drive.google.com/file/d/1TTJzXi0dWYHVCrZM8vWoZzKWPfIF0ErB/view?usp=sharing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhinglishRoberta.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ML/Project_ML_Group10/hinglishutils.py:95\u001b[0m, in \u001b[0;36mget_files_from_gdrive\u001b[0;34m(url, fname)\u001b[0m\n\u001b[1;32m     93\u001b[0m gdown\u001b[38;5;241m.\u001b[39mdownload(url, fname, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     tf \u001b[38;5;241m=\u001b[39m \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     tf\u001b[38;5;241m.\u001b[39mextractall()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/tarfile.py:1783\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     saved_pos \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ReadError, CompressionError):\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/tarfile.py:1847\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompressionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip module is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1847\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_final/lib/python3.8/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hinglishRoberta.tar'"
     ]
    }
   ],
   "source": [
    "get_files_from_gdrive(\"https://drive.google.com/file/d/1TTJzXi0dWYHVCrZM8vWoZzKWPfIF0ErB/view?usp=sharing\", \n",
    "                      \"hinglishRoberta.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling \n",
    "The run_language_modeling.py is taken from [huggingface/transformers/examples/language-modeling](https://github.com/huggingface/transformers/tree/master/examples/language-modeling) \n",
    "\n",
    "- output_dir - directory to save your model files\n",
    "- model_type - Type of transfomer model bert/distilbert/roberta\n",
    "- model_name_or_path - name of the model. Model names can be found [here(official and community-uploaded)](https://huggingface.co/models) and [here(official)](https://huggingface.co/transformers/pretrained_models.html)\n",
    "- do_train\n",
    "- do_eval\n",
    "- train_data_file - path to train data text file\n",
    "- eval_data_file - path to eval data text file\n",
    "- mlm - This is used for BERT-based transforers. This stands for masked LMs  \n",
    "- num_train_epochs - Number of training epochs\n",
    "- save_total_limit - This saves the latest n checkpoints where n is the integer you provide to this parameter. We used 2 here because of size constrains on colab\n",
    "- overwrite_output_dir - overwrites the output folder that already exists/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_language_modeling.py --output_dir=bert --model_type=bert --model_name_or_path=bert-base-multilingual-cased --do_train --train_data_file=train_lm_data.txt --do_eval --eval_data_file=dev_lm_data.txt --mlm  --num_train_epochs 3 --save_total_limit 2 --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_language_modeling.py --output_dir=distilbert --model_type=distilbert --model_name_or_path=distilbert-base-cased --do_train --train_data_file=train_lm_data.txt --do_eval --eval_data_file=dev_lm_data.txt --mlm  --num_train_epochs 3 --save_total_limit 2 --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_language_modeling.py --output_dir=roberta --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=train_lm_data.txt --do_eval --eval_data_file=dev_lm_data.txt --mlm  --num_train_epochs 3 --save_total_limit 2 --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HinglishBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hinglish import HinglishTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"bert\",\n",
    "    batch_size=16,\n",
    "    attention_probs_dropout_prob=0.4,\n",
    "    hidden_dropout_prob=0.3,\n",
    "    learning_rate=5e-07,\n",
    "    adam_epsilon=1e-08\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HinglishDistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"distilbert\",\n",
    "    batch_size=16,\n",
    "    attention_probs_dropout_prob=0.6,\n",
    "    hidden_dropout_prob=0.6,\n",
    "    learning_rate=3e-05,\n",
    "    adam_epsilon=1e-08,\n",
    "    lm_model_dir=\"distilBert6\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HinglishRoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"roberta\",\n",
    "    batch_size=16,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    learning_rate=4e-05,\n",
    "    adam_epsilon=5e-08,\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"distilbert\",\n",
    "    batch_size=16,\n",
    "    attention_probs_dropout_prob=0.8,\n",
    "    hidden_dropout_prob=0.4,\n",
    "    learning_rate=3.02e-05,\n",
    "    adam_epsilon=9.35e-05,\n",
    "    lm_model_dir=\"distilBert6\",\n",
    "    wname = \"Ensemble DistilBert1\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"distilbert\",\n",
    "    batch_size=4,\n",
    "    attention_probs_dropout_prob=0.6,\n",
    "    hidden_dropout_prob=0.2,\n",
    "    learning_rate=5.13e-05,\n",
    "    adam_epsilon=9.72e-05,\n",
    "    lm_model_dir=\"distilBert6\",\n",
    "    wname = \"Ensemble DistilBert2\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"distilbert\",\n",
    "    batch_size=16,\n",
    "    attention_probs_dropout_prob=0.4,\n",
    "    hidden_dropout_prob=0.6,\n",
    "    learning_rate=4.74e-05,\n",
    "    adam_epsilon=4.09e-05,\n",
    "    lm_model_dir=\"distilBert6\",\n",
    "    wname = \"Ensemble DistilBert3\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"bert\",\n",
    "    batch_size=4,\n",
    "    attention_probs_dropout_prob=0.6,\n",
    "    hidden_dropout_prob=0.2,\n",
    "    learning_rate=5.13e-05,\n",
    "    adam_epsilon=9.72e-05,\n",
    "    lm_model_dir=\"distilBert6\",\n",
    "    wname = \"Ensemble Bert1\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinglishbert = HinglishTrainer(\n",
    "    \"bert\",\n",
    "    batch_size=4,\n",
    "    attention_probs_dropout_prob=0.7,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    learning_rate=5.01e-05,\n",
    "    adam_epsilon=4.79e-05,\n",
    "    lm_model_dir=\"distilBert6\",\n",
    "    wname = \"Ensemble Bert2\"\n",
    ")\n",
    "hinglishbert.train()\n",
    "hinglishbert.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
